{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: \n",
    "\n",
    "#### HOW TO CLEAN DATA WITH PYTHON\n",
    "\n",
    "**Cleaning US Census Data**\n",
    "\n",
    "You just got hired as a Data Analyst at the Census Bureau, which collects census data and creates interesting visualizations and insights from it.\n",
    "\n",
    "The person who had your job before you left you all the data they had for the most recent census. It is in multiple csv files. They didn’t use pandas, they would just look through these csv files manually whenever they wanted to find something. Sometimes they would copy and paste certain numbers into Excel to make charts.\n",
    "\n",
    "The thought of it makes you shiver. This is not scalable or repeatable.\n",
    "\n",
    "Your boss wants you to make some scatterplots and histograms by the end of the day. Can you get this data into pandas and into reasonable shape so that you can make these histograms?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspect the Data!**\n",
    "\n",
    "**1.** The first visualization your boss wants you to make is a scatterplot that shows average income in a state vs proportion of women in that state.\n",
    "\n",
    "Open some of the census csv files in the navigator. How are they named? What kind of information do they hold? Will they help us make this graph?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** It will be easier to inspect this data once we have it in a DataFrame. You can’t even call .head() on these csvs! How are you supposed to read them?\n",
    "   Using glob, loop through the census files available and load them into DataFrames. Then, concatenate all of those DataFrames together into one DataFrame, called something like us_census."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"states*.csv\")\n",
    "\n",
    "df_list = [pd.read_csv(fname, index_col=0) for fname in files]  \n",
    "us_census = pd.concat(df_list, ignore_index=True)                  \n",
    "\n",
    "us_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Look at the .columns and the .dtypes of the us_census DataFrame. Are those datatypes going to hinder you as you try to make histograms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also get above required output with 'info()' function\n",
    "# us_census.info()\n",
    "\n",
    "print(us_census.dtypes)\n",
    "print(us_census.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Look at the .head() of the DataFrame so that you can understand why some of these dtypes are objects instead of integers or floats.\n",
    "Start to make a plan for how to convert these columns into the right types for manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regex to the Rescue**\n",
    "\n",
    "**5.** Use regex to turn the Income column into a format that is ready for conversion into a numerical type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First method to achieve the above stated goal\n",
    "#split_df = us_census['Income'].str.split('$', expand= True)\n",
    "#us_census['Income'] =  pd.to_numeric(split_df[1])\n",
    "\n",
    "# 2nd method\n",
    "\n",
    "replace_df = us_census.Income.replace('[$,]','',regex=True)\n",
    "us_census['Income'] =  pd.to_numeric(replace_df)\n",
    "#print(us_census.head())\n",
    "#print(us_census.dtypes)\n",
    "us_census['Income'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Look at the GenderPop column. We are going to want to separate this into two columns, the Men column, and the Women column.\n",
    "Split the column into those two new columns using str.split and separating out those results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_genders = us_census['GenderPop'].str.split('_', expand=True)\n",
    "print(sep_genders.head())\n",
    "us_census['Men'] = sep_genders[0]\n",
    "us_census['Women'] = sep_genders[1]\n",
    "\n",
    "us_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** Convert both of the columns into numerical datatypes.\n",
    "There is still an M or an F character in each entry! We should remove those before we convert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_census['Men'] = pd.to_numeric(us_census['Men'].apply(lambda x:x[:-1]))\n",
    "us_census['Women'] = pd.to_numeric(us_census['Women'].apply(lambda x:x[:-1]))\n",
    "\n",
    "us_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** Now you should have the columns you need to make the graph and make sure your boss does not slam a ruler angrily on your desk because you’ve wasted your whole day cleaning your data with no results to show!\n",
    "\n",
    "    Use matplotlib to make a scatterplot!\n",
    "\n",
    "    plt.scatter(the_women_column, the_income_column) \n",
    "    Remember to call plt.show() to see the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(us_census.Women, us_census.Income)\n",
    "plt.xlabel('Female Population')\n",
    "plt.ylabel('Income')\n",
    "plt.title('Female Population and Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.** Did you get an error? These monstrous csv files probably have nan values in them! Print out your column with the number of women per state to see.\n",
    "\n",
    "We can fill in those nans by using pandas’ .fillna() function.\n",
    "\n",
    "You have the TotalPop per state, and you have the Men per state. As an estimate for the nan values in the Women column, you could use the TotalPop of that state minus the Men for that state.\n",
    "\n",
    "Print out the Women column after filling the nan values to see if it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(us_census['Women'])\n",
    "us_census['Women'] = us_census['Women'].fillna(us_census.TotalPop - us_census.Men)\n",
    "us_census['Women'] = us_census['Women'].astype(int)     # to convert from float to int\n",
    "print(us_census['Women'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.** We forgot to check for duplicates! Use .duplicated() on your census DataFrame to see if we have duplicate rows in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(us_census.duplicated('State'))\n",
    "print(us_census.duplicated().value_counts())\n",
    "us_census[us_census.duplicated('State')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11.** Drop those duplicates using the .drop_duplicates() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(us_census.drop_duplicates())\n",
    "us_census = us_census.drop_duplicates(ignore_index=True)\n",
    "\n",
    "us_census.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12.** Make the scatterplot again. Now, it should be perfect! Your job is secure, for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(us_census.Women, us_census.Income)\n",
    "plt.xlabel('Female Population')\n",
    "plt.ylabel('Income')\n",
    "plt.title('Female Population and Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms of Races\n",
    "\n",
    "**13.** Now, your boss wants you to make a bunch of histograms out of the race data that you have. Look at the .columns again to see what the race categories are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_census.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14.** Try to make a histogram for each one!\n",
    "\n",
    "You will have to get the columns into numerical format, and those percentage signs will have to go.\n",
    "\n",
    "Don’t forget to fill the nan values with something that makes sense! You probably dropped the duplicate rows when making your last graph, but it couldn’t hurt to check for duplicates again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_census.Hispanic = us_census.Hispanic.replace('[%,]','',regex=True)\n",
    "us_census.Hispanic = pd.to_numeric(us_census.Hispanic)\n",
    "\n",
    "us_census.White = us_census.White.replace('[%,]','',regex=True)\n",
    "us_census.White = pd.to_numeric(us_census.White)\n",
    "\n",
    "us_census.Black = us_census.Black.replace('[%,]','',regex=True)\n",
    "us_census.Black = pd.to_numeric(us_census.Black)\n",
    "\n",
    "us_census.Native = us_census.Native.replace('[%,]','',regex=True)\n",
    "us_census.Native = pd.to_numeric(us_census.Native)\n",
    "\n",
    "us_census.Asian = us_census.Asian.replace('[%,]','',regex=True)\n",
    "us_census.Asian = pd.to_numeric(us_census.Asian)\n",
    "\n",
    "us_census.Pacific = us_census.Pacific.replace('[%,]','',regex=True)\n",
    "us_census.Pacific = pd.to_numeric(us_census.Pacific)\n",
    "\n",
    "print(us_census.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check for missing values values before plotting\n",
    "print(us_census.Hispanic.isna().value_counts())\n",
    "print(us_census.White.isna().value_counts())\n",
    "print(us_census.Black.isna().value_counts())\n",
    "print(us_census.Native.isna().value_counts())\n",
    "print(us_census.Asian.isna().value_counts())\n",
    "print(us_census.Pacific.isna().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values \n",
    "us_census['Pacific'] = us_census['Pacific'].fillna(100 - (us_census['Hispanic'] +us_census['Black']+us_census['White']+us_census['Native']+us_census['Asian']  ))\n",
    "\n",
    "print(us_census.Pacific.isna().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(us_census.Hispanic, bins=15, label= \"hispanic\")\n",
    "plt.hist(us_census.Black, bins=15,label= \"black\")\n",
    "plt.hist(us_census.White, bins=15,label= \"white\")\n",
    "plt.hist(us_census.Native, bins=15,label= \"native\")\n",
    "plt.hist(us_census.Asian, bins=15,label= \"asian\")\n",
    "plt.hist(us_census.Pacific, bins=15, label= \"pacific\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2:\n",
    "\n",
    "### LEARN DATA ANALYSIS WITH PANDAS\n",
    "\n",
    "**Petal Power Inventory**\n",
    "You’re the lead data analyst for a chain of gardening stores called Petal Power. Help them analyze their inventory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer Customer Emails**\n",
    "\n",
    "**1.** Data for all of the locations of Petal Power is in the file inventory.csv. Load the data into a DataFrame called inventory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory = pd.read_csv(\"inventory.csv\")\n",
    "inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Inspect the first 10 rows of inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** The first 10 rows represent data from your Staten Island location. Select these rows and save them to staten_island."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staten_island = inventory.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** A customer just emailed you asking what products are sold at your Staten Island location. Select the column product_description from staten_island and save it to the variable product_request.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_request = staten_island.product_description     # another way is:  staten_island['product_description']\n",
    "product_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Another customer emails to ask what types of seeds are sold at the Brooklyn location. Select all rows where location is equal to Brooklyn and product_type is equal to seeds and save them to the variable seed_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_request = inventory[(inventory.location == 'Brooklyn') & (inventory.product_type == 'seeds')]\n",
    "seed_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inventory**\n",
    "\n",
    "**6.** Add a column to inventory called in_stock which is True if quantity is greater than 0 and False if quantity equals 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_stock = lambda x: True if x > 0 else False\n",
    "inventory['in_stock'] = inventory['quantity'].apply(in_stock)  # we could also use 'map' function\n",
    "\n",
    "inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** Petal Power wants to know how valuable their current inventory is.Create a column called total_value that is equal to price multiplied by quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inventory['total_value'] = inventory['price'] * inventory['quantity']     // This is one way\n",
    "\n",
    "#inventory['total_value'] = inventory['price'].multiply(inventory['quantity']) // another way\n",
    "# Below is through lambda function\n",
    "\n",
    "total_value = lambda x: x.price * x.quantity\n",
    "\n",
    "inventory['total_value'] = inventory.apply(total_value, axis = 1)\n",
    "inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** The Marketing department wants a complete description of each product for their catalog. The following lambda function combines product_type and product_description into a single string:\n",
    "\n",
    "combine_lambda = lambda row: \\\n",
    "    '{} - {}'.format(row.product_type,\n",
    "                     row.product_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_lambda = lambda row: '{} - {}'.format(row.product_type,row.product_description)\n",
    "combine_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.** Using combine_lambda, create a new column in inventory called full_description that has the complete description of each product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory['full_description'] = inventory.apply(combine_lambda, axis = 1)\n",
    "inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
